{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c069360-074a-445e-a3f9-9fd44970471a",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "Scaling changes the range of features in our dataset.\n",
    "\n",
    "Scaling\n",
    "\n",
    "- why\n",
    "    - some model types can be thrown off by different feature scales\n",
    "    - improves most model's implementation\n",
    "    - visualize the combination of 2 variables with different scales\n",
    "    - a better interpretation of the data (e.g. log scaling)\n",
    "    - combining features\n",
    "- when\n",
    "    - data prep / exploration\n",
    "    - pipeline: prep\n",
    "    - lifecycle: prep/exploration\n",
    "    - when one of the conditions above is met. Otherwise, it's better to work with the original units\n",
    "- where\n",
    "    - the training dataset\n",
    "    - usually just the independent variables\n",
    "    - indep vars are scaled independently, i.e. the scaling of one feature doesn't affect the scaling of another\n",
    "    - scale whatever goes into the model\n",
    "- how\n",
    "    - `sklearn.preprocessing` -- requires 2d array\n",
    "    - make the thing, fit the thing, use the thing\n",
    "    - `.fit` to learn parameters, `.transform` to apply the scaling\n",
    "    - seperate scaled dataframes and/or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4ad091-312f-4ba6-babd-fdb7e2981378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pydataset\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a373a-110c-4087-be47-65bf8306ebda",
   "metadata": {},
   "source": [
    "## Why Scale? A Motivating Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09551615",
   "metadata": {},
   "source": [
    "Goals: predict the flavor of ice cream\n",
    "\n",
    "Note: for the purposes of the demo, we will only be looking at train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c134c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://gist.githubusercontent.com/zgulde/\\\n",
    "66989745314d2c68ab62fae13743f094/raw/71635c6281b5e2a36e3eb4578cab277eb09743ec/train.csv')\n",
    "validate = pd.read_csv('https://gist.githubusercontent.com/zgulde/\\\n",
    "66989745314d2c68ab62fae13743f094/raw/71635c6281b5e2a36e3eb4578cab277eb09743ec/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d7c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (90, 3)\n",
      "validate shape: (10, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train shape:', train.shape)\n",
    "print('validate shape:', validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a44a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flavor</th>\n",
       "      <th>pints</th>\n",
       "      <th>n_sprinkles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>7.675963</td>\n",
       "      <td>921.808798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>7.129386</td>\n",
       "      <td>1186.329821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pistachio</td>\n",
       "      <td>12.182332</td>\n",
       "      <td>443.310335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pistachio</td>\n",
       "      <td>13.955832</td>\n",
       "      <td>832.502384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>10.748216</td>\n",
       "      <td>892.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flavor      pints  n_sprinkles\n",
       "0  blueberry   7.675963   921.808798\n",
       "1  blueberry   7.129386  1186.329821\n",
       "2  pistachio  12.182332   443.310335\n",
       "3  pistachio  13.955832   832.502384\n",
       "4  chocolate  10.748216   892.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c652848-88d1-419e-9701-f9816ecd1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate = train[['pints', 'n_sprinkles']], validate[['pints', 'n_sprinkles']]\n",
    "y_train, y_validate = train.flavor, validate.flavor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f552c6-6881-4970-8fb5-e5a717729dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the thing\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fit the thing\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# use the thing\n",
    "model.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98981a",
   "metadata": {},
   "source": [
    "### Scale the data\n",
    "1. make the thing\n",
    "2. fit the thing\n",
    "3. use the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37da69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1665e86-513a-4ef3-947c-614c1d2a13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making our scaler\n",
    "\n",
    "\n",
    "#fitting our scaler \n",
    "# AND!!!!\n",
    "#using the scaler on train\n",
    "\n",
    "#using our scaler on validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e002e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6861cb",
   "metadata": {},
   "source": [
    "#### now re-fit our model with scaled data and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce0fc906-7236-46a4-85de-9f1118309557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the thing (its already made)\n",
    "\n",
    "#fit the thing\n",
    "\n",
    "\n",
    "#use the thing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff12c7-265b-4190-9384-97fc59db0de5",
   "metadata": {},
   "source": [
    "What's going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fb8514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74ad499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=train, y='n_sprinkles', x='pints', hue='flavor');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "713914b7-f25f-4dcf-8af8-4fdd52afd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(data=train, y='n_sprinkles', x='pints', hue='flavor')\n",
    "# plt.xlim(-800, 800);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372900b4-0f50-4fc1-8a81-622c4272eb9c",
   "metadata": {},
   "source": [
    "Distance between 2 points\n",
    "\n",
    "$$\n",
    "\\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89acc8-659f-4d1e-a286-3df74c2b4561",
   "metadata": {},
   "source": [
    "### Another Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf819f4",
   "metadata": {},
   "source": [
    "Dataset: demographics and self-reported scores for the ACT, SAT Verbal, and SAT Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0e8fae-c0c5-43f4-bea7-09b7fab0084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pydataset.data('sat.act')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c57337",
   "metadata": {},
   "source": [
    "#### how does gender relate each test score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f3b3af-6d22-4842-86c9-08ddeb412368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['gender', 'ACT', 'SATV', 'SATQ']].groupby('gender').mean()\n",
    "# .plot.bar(figsize=(11, 6), ec='black', width=.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47747da3",
   "metadata": {},
   "source": [
    "#### lets scale our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baafae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0976a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining my columns explicitly to scale\n",
    "cols = ['ACT', 'SATQ', 'SATV']\n",
    "\n",
    "# making my scaler object\n",
    "\n",
    "\n",
    "# calling my fit_transform (note i dont have a train/test)\n",
    "# reassign those transformed values back into the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f5208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "085a4902-9dad-4e56-891d-8e071f6b0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping and plotting as we did before\n",
    "# df[['gender', 'ACT', 'SATV', 'SATQ']].groupby('gender').mean()\n",
    "# .plot.bar(figsize=(11, 6), ec='black', width=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898f15b-5a5b-4616-88f8-57a6dac887b0",
   "metadata": {},
   "source": [
    "## Linear Scaling\n",
    "\n",
    "- Units are changed, but the distance between points is preserved.\n",
    "\n",
    "- MinMax: everything between 0 and 1\n",
    "\n",
    "    $$ x' = \\frac{x - \\text{max}(x)}{\\text{max}(x) - \\text{min}(x)} $$\n",
    "\n",
    "- Standard: a zscore, standard deviations from the mean, **center** + **scale**\n",
    "\n",
    "    $$ x' = \\frac{x - \\bar{x}}{s_x} $$\n",
    "\n",
    "    - **centering**: subtracting the mean\n",
    "    - **scaling**: dividing by the standard deviation\n",
    "\n",
    "- Robust: robust to and preserves outliers\n",
    "\n",
    "    $$ x' = \\frac{x - \\text{med}(x)}{\\text{IQR}_x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43435167-b883-4a1a-978d-e830b2a3569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_example = pd.DataFrame()\n",
    "scaling_example['x1'] = np.arange(1, 11)\n",
    "scaling_example['x2'] = [-100, -1, 0, 1, 2, 3, 4, 5, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9238b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab28a84b-645f-4ac5-a3a0-577429c7167d",
   "metadata": {},
   "source": [
    "When scaling a single column, make sure to pass it to the scaler object as a dataframe, not as a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a03ebc-f2c2-4ca2-9fe5-1a271b7403dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling this\n",
    "# one column:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2948b3",
   "metadata": {},
   "source": [
    "#### linear scalers for both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4262f5a-94a3-42ce-b889-55f809d73e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaling_example[['x1_minmax', 'x2_minmax']] = scaler.fit_transform(scaling_example[['x1','x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "99483969-09d9-4da8-ab66-09ac7b5e39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaling_example[['x1_standard', 'x2_standard']] = scaler.fit_transform(scaling_example[['x1','x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "205aa092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9bcc236-815c-4d8e-9e3d-8daba13b32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "# scaling_example[['x1_robust', 'x2_robust']] = scaler.fit_transform(scaling_example[['x1', 'x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "675c59cf-ac9b-41fc-8ca4-58404d368c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling_example[sorted(scaling_example)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bec6f794-fc23-4a1d-8f9f-bd7ff0b49bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(scaling_example.x1, scaling_example.x2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e15cce3f-0753-4fbc-b1be-a98d48a42b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(scaling_example.x1_minmax, scaling_example.x2_minmax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebcccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(scaling_example.x1_robust, scaling_example.x2_robust);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e50812ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(scaling_example.x1_standard, scaling_example.x2_standard);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8010d53-b92a-4f41-ae48-7b77a015b592",
   "metadata": {},
   "source": [
    "## Non-linear Scaling\n",
    "\n",
    "- The distance between points is **not** preserved, but order is\n",
    "- Not as common as linear scalers\n",
    "- In sklearn: \n",
    "    - power transformation: box-cox, yeo-johnson;\n",
    "    - quantile transformation\n",
    "- Log\n",
    "\n",
    "    $$ x' = \\log_b{x} $$\n",
    "\n",
    "    $$ b^{x'} = x $$\n",
    "\n",
    "    Sometimes you can just set the x/y scale w/ matplotlib instead of\n",
    "    actually transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12da73f2-cabb-4ea5-9297-2018d18d3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n = 100\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['x1'] = np.random.randn(n)\n",
    "df['x2'] = 10 ** (df.x1 + np.random.randn(n) * .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d38923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e60aaba-ef6b-4a15-a703-95844f84380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,5))\n",
    "# ax.scatter(df.x1, df.x2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dbbebdb-99dd-41ae-bd62-afaf87686a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,5))\n",
    "# ax.scatter(df.x1, df.x2)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b5a0b-6e0e-4314-ac31-0841593fa2a0",
   "metadata": {},
   "source": [
    "If we want to predict $y$ based on $x$ and there is a linear relationship between them, the model\n",
    "\n",
    "$$ y = mx + b $$\n",
    "\n",
    "works pretty well.\n",
    "\n",
    "However, if the relationship is exponential, that model does not make great predictions, but instead we could transform x:\n",
    "\n",
    "$$ y = m(log(x)) + b $$\n",
    "\n",
    "And still get decent predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0cf33",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "- Generally use unscaled data for exploration\n",
    "- Use scaled data for modeling, typically min-max scaler\n",
    "- Learn parameters for scaling from the training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93468536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
